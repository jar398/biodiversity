
The first thing I'd like to talk about is ontologies.  That may not be
quite the right word because I think my subject matter encroaches on
epistemology; but I'll stick with it for the time being.

Many people now say "ontology" when they mean "controlled vocabulary"
or "digital file expressing an ontology in
[OWL](https://en.wikipedia.org/wiki/Web_Ontology_Language)".  I mean
it in a much fuzzier and more comprehensive sense: an ontology is a
theory of what is.  That is a bit vague. Operationally, it is a theory
that tells you what is fruitful to talk about and what is not.

[Here](https://plato.stanford.edu/entries/logic-ontology/)
is the relevant SEP article.

An ontology (a theory of what is) manifests as a language, with terms
and means of combining them.  Terms might refer to individuals and
classes (and the ontology describes, predicts, or dictates how these
ought to be interpreted).  Means of combination might be things like
the membership of an individual in a class.

Of course an ontology need not revolve around individuals and classes.
It might have (or be) an entirely different theory of what is.  That
is what makes it an ontology.  But individuals/classes is a common way
to organize discourse under an ontology.

I say ontologies lean towards epistemology because they not only tell
you what is, they tell you what can be true of what is.  Again, this
is done through some language associated with the ontology, which
would have a grammar for sentences.

I love the expressions "is that a thing?", "that's not a thing." and
so on because they give evidence that ontology is (or ontologies are)
an everyday concern, not some obscure and unimportant branch of
academic philosophy.

I'm interested in writing computer programs that do inference (a word
for another page), and computers are just "symbol pushers" and "don't
understand anything".  This means that the way that propositions are
expressed (i.e. the way a person transcribes something they know -
data - into a form the computer can "push") is quite important.  The
rules of inference, i.e. logic, that respect an ontological theory is
also quite important, since this is how a computer can "push symbols"
and come up with new combinations of them that can be interpreted as
testable claims about the world.

Forward references, perhaps: i.e. I am inclined to write additional
pages around these words:
 * proposition
 * sentence
 * express
 * interpret
 * class
 * individual

I don't want to meander too much, so I will try to be judicious about
creating new pages, but sometimes I get impulsive about writing.  If
the hyperlinks really work then you should be able to read only what
you're interested in and get the part of the story that you care
about.

I haven't decided what [2](2) will be about, but I suppose you could
go see what's there.
